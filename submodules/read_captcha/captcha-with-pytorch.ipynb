{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import const\n",
    "import my_datasets\n",
    "from my_models import MyResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    count_correct = 0\n",
    "    count_all = 0\n",
    "    _ACS = np.array(const.ALL_CHAR_SET)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, (img, _, label) in enumerate(dataloader):\n",
    "            img = img.cuda()\n",
    "            pred = model(img).reshape((-1, len(const.ALL_CHAR_SET), const.MAX_CAPTCHA)).cpu()\n",
    "        \n",
    "            c = [''.join(line) for line in _ACS[pred.argmax(axis=1)]]\n",
    "            count_correct += sum([(lambda x, y: (x == y))(x, y) for x, y in zip(c, label)])\n",
    "            count_all += len(c)\n",
    "    return count_correct / count_all\n",
    "\n",
    "def train(model, dataloader, loss_func, optimizer):\n",
    "    model.train()\n",
    "    loss_epoch = 0\n",
    "    for img, label_idx, label in dataloader:\n",
    "        img = img.cuda()\n",
    "        label_idx = label_idx.cuda()\n",
    "        pred = model(img).reshape((-1, len(const.ALL_CHAR_SET), const.MAX_CAPTCHA))\n",
    "\n",
    "        loss = loss_func(pred, label_idx)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.item()\n",
    "    return loss_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_NAMES = my_datasets.get_data_names()\n",
    "DATA_NAMES = list(my_datasets.DATA_DIRS.keys())\n",
    "#train_data_names = (DATA_NAMES[2], ) #'all'\n",
    "#train_dataloader_name = 'train_dataloader_'+str(train_dataloader_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('captcha-images', 'captcha-09az'), ('captcha-images', 'capitalized'), ('captcha-images', 'capital-color'), ('captcha-09az', 'capitalized'), ('captcha-09az', 'capital-color'), ('capitalized', 'capital-color')]\n"
     ]
    }
   ],
   "source": [
    "train_data_list = [tuple(DATA_NAMES[i] for i in sorted(indexes)) for indexes in [[0,1], [0,2], [0, 3], [1,2], [1,3], [2,3]]]\n",
    "print(train_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "28b40e0cd24527661150bd99a1a8a244fe64d961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('captcha-images', 'capitalized')]\n",
      "eopch: 0 loss: 364.7583210468292 test: [0.0, 0.0, 0.0, 0.0] mean: 0.0\n",
      "eopch: 1 loss: 353.01735186576843 test: [0.0, 0.0, 0.0, 0.0] mean: 0.0\n",
      "eopch: 2 loss: 324.7808816432953 test: [0.0, 0.0, 0.0, 0.0] mean: 0.0\n",
      "eopch: 3 loss: 271.95271396636963 test: [0.0, 0.0, 0.0, 0.0] mean: 0.0\n",
      "eopch: 4 loss: 208.397127866745 test: [0.0, 0.0, 0.0, 0.0] mean: 0.0\n",
      "eopch: 5 loss: 148.61644446849823 test: [0.062, 0.0, 0.015, 0.0] mean: 0.01925\n",
      "eopch: 6 loss: 96.19722467660904 test: [0.278, 0.0, 0.07, 0.0] mean: 0.08700000000000001\n",
      "eopch: 7 loss: 58.272410809993744 test: [0.348, 0.0, 0.195, 0.0] mean: 0.13574999999999998\n",
      "eopch: 8 loss: 35.7857563495636 test: [0.596, 0.0, 0.47, 0.0] mean: 0.26649999999999996\n",
      "eopch: 9 loss: 21.831040129065514 test: [0.454, 0.0, 0.535, 0.0] mean: 0.24725000000000003\n",
      "eopch: 10 loss: 16.150591865181923 test: [0.124, 0.0, 0.19, 0.0] mean: 0.0785\n",
      "eopch: 11 loss: 13.543409921228886 test: [0.772, 0.0, 0.83, 0.0] mean: 0.40049999999999997\n",
      "eopch: 12 loss: 7.006783742457628 test: [0.81, 0.0, 0.84, 0.0] mean: 0.4125\n",
      "eopch: 13 loss: 4.802048575133085 test: [0.798, 0.0, 0.765, 0.0] mean: 0.39075000000000004\n",
      "eopch: 14 loss: 4.652121871709824 test: [0.828, 0.0, 0.835, 0.0] mean: 0.41574999999999995\n",
      "eopch: 15 loss: 3.025324020534754 test: [0.824, 0.0, 0.92, 0.0] mean: 0.436\n",
      "eopch: 16 loss: 2.163589844480157 test: [0.86, 0.0, 0.92, 0.0] mean: 0.445\n",
      "eopch: 17 loss: 1.5996140046045184 test: [0.876, 0.0, 0.915, 0.0] mean: 0.44775\n",
      "eopch: 18 loss: 1.3136362209916115 test: [0.9, 0.0, 0.935, 0.0] mean: 0.45875\n"
     ]
    }
   ],
   "source": [
    "def process(model, loss_func, optimizer, train_data_names):\n",
    "    #train_dataloader = dataloaders[train_dataloader_name]\n",
    "    train_dataloader = my_datasets.get_dataloader(train_data_names, TRAIN_BATCH_SIZE, True)\n",
    "\n",
    "    model.train()\n",
    "    best_acc = 0\n",
    "    log = list()\n",
    "    save_dir = const.RECOGNIZER_DIR / '+'.join(train_data_names)\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for epoch in range(40):\n",
    "        loss = train(model, train_dataloader, loss_func, optimizer)\n",
    "        print('eopch:', epoch, 'loss:', loss, end=' ')\n",
    "\n",
    "        acc = [evaluate(model, my_datasets.get_dataloader((name, ), TEST_BATCH_SIZE, False)) for name in my_datasets.DATA_DIRS.keys()]\n",
    "        mean = sum(acc) / len(acc)\n",
    "        if mean > best_acc:\n",
    "            best_acc = mean\n",
    "        #    torch.save(model.state_dict(), str(const.RECOGNIZER_DIR/'{}.pt'.format(train_dataloader_name)))\n",
    "        torch.save(model.state_dict(), str(save_dir / '{}.pt'.format(epoch)))\n",
    "        log.append(dict(epoch=epoch, loss=loss, **{'acc{}'.format(i): val for i, val in enumerate(acc)}))\n",
    "        with (save_dir / 'log.json'.format()).open('w') as f:\n",
    "            json.dump(log, f)\n",
    "        print('test:', acc, 'mean:', mean)\n",
    "        if sum(acc) == 0:\n",
    "            continue\n",
    "        elif sum(acc) / len(train_data_names) > 0.9:\n",
    "            break\n",
    "\n",
    "#train_data_list = [tuple(DATA_NAMES[i] for i in sorted(indexes)) for indexes in [[0,1], [0,2], [1,2], [1,3], [2,3]]]\n",
    "train_data_list = [tuple(DATA_NAMES[i] for i in sorted(indexes)) for indexes in [[0, 2]]]\n",
    "#train_data_list = train_data_list[1:2]\n",
    "\n",
    "print(train_data_list)\n",
    "\n",
    "for names in train_data_list:\n",
    "    out_features = len(const.ALL_CHAR_SET) * const.MAX_CAPTCHA\n",
    "    model = MyResNet(out_features)\n",
    "    model.cuda()\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "    process(model, loss_func, optimizer, names)\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee252c547d499faa13b42c8e5bacb5d07feea9557900722589fb9cc43695bfe0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('captcha-rsSqJZ6U')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
